{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwsfKIbeMgg2"
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai pandas[jinja2] spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRjCJ1rLMtpb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJt4zPEPM3xK"
   },
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKx9vcE8M-RJ"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "# Configurar la API de OpenAI con tu clave\n",
    "openai.api_key = 'your-token'\n",
    "\n",
    "# Configurar el modelo GPT-4 Mini\n",
    "gpt4mini_model = \"gpt-4o-mini\"  # Asegúrate de que este sea el modelo correcto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEL9EgefNJ1_"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Response,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.evaluation import CorrectnessEvaluator\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9_q8EHGNRHs"
   },
   "outputs": [],
   "source": [
    "# gpt-4\n",
    "gpt4 = OpenAI(temperature=0, model=gpt4mini_model)\n",
    "evaluator = CorrectnessEvaluator(llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvUOcHXLl4j0"
   },
   "outputs": [],
   "source": [
    "#Seleccionamos el corpus correspondiente\n",
    "corpus = pd.read_csv('respuestas_gpt35.csv')\n",
    "corpus = pd.read_csv('respuestas_gpt4.csv')\n",
    "corpus = pd.read_csv('respuestas_mixtral.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ghrjy6WnOiky"
   },
   "source": [
    "Los resultados son entre 1 y 5, siendo el 5 el máximo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVR_6E0PPdgO"
   },
   "source": [
    "Aplicamos el cálculo del score a todos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bl-P346HOrg9"
   },
   "outputs": [],
   "source": [
    "corpus['Correcteness_score'] = corpus.apply(\n",
    "    lambda x: evaluator.evaluate(\n",
    "        query=x['pregunta_generada'],\n",
    "        response=x['respuesta'],\n",
    "        reference=x['frase']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['Correcteness_score'] = corpus['Correcteness_general'].apply(lambda x: x.score)\n",
    "corpus['Correcteness_feedback'] = corpus['Correcteness_feedback'].apply(lambda x: x.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dv7EA4gEPs51"
   },
   "outputs": [],
   "source": [
    "corpus.to_csv('Score_mistral_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyOkEWd0gIyDbJVy2wR/ThPD",
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
